{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer, pipeline, AutoModel, AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan Did they post their votes for Hillary alre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72129</th>\n",
       "      <td>Russians steal research on Trump in hack of U....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72130</th>\n",
       "      <td>WATCH: Giuliani Demands That Democrats Apolog...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72131</th>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72132</th>\n",
       "      <td>Trump tussle gives unpopular Mexican leader mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72133</th>\n",
       "      <td>Goldman Sachs Endorses Hillary Clinton For Pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72134 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      LAW ENFORCEMENT ON HIGH ALERT Following Threat...      1\n",
       "1      nan Did they post their votes for Hillary alre...      1\n",
       "2      UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...      1\n",
       "3      Bobby Jindal, raised Hindu, uses story of Chri...      0\n",
       "4      SATAN 2: Russia unvelis an image of its terrif...      1\n",
       "...                                                  ...    ...\n",
       "72129  Russians steal research on Trump in hack of U....      0\n",
       "72130   WATCH: Giuliani Demands That Democrats Apolog...      1\n",
       "72131  Migrants Refuse To Leave Train At Refugee Camp...      0\n",
       "72132  Trump tussle gives unpopular Mexican leader mu...      0\n",
       "72133  Goldman Sachs Endorses Hillary Clinton For Pre...      1\n",
       "\n",
       "[72134 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"WELFake_Dataset.csv\").drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "df['text'] = df['title'].astype(str) + \" \" + df['text']\n",
    "df = df.drop(columns=[\"title\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"].map(preprocess_function)\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings, test_encodings, train_labels, test_labels = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_dict(X):\n",
    "    X_ = {\"input_ids\" : [], \"attention_mask\" : []}\n",
    "    for i in X:\n",
    "        X_[\"input_ids\"].append(i[\"input_ids\"])\n",
    "        X_[\"attention_mask\"].append(i[\"attention_mask\"])\n",
    "\n",
    "    return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Labels_list(y):\n",
    "    y_ = []\n",
    "    for i in y:\n",
    "        y_.append(i)\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings_ = Text_dict(train_encodings)\n",
    "train_encodings = train_encodings_\n",
    "test_encodings_ = Text_dict(test_encodings)\n",
    "test_encodings = test_encodings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_ = Labels_list(train_labels)\n",
    "train_labels = train_labels_\n",
    "test_labels_ = Labels_list(test_labels)\n",
    "test_labels = test_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fraud_EMail_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.encodings[\"input_ids\"][idx])\n",
    "        target_ids = torch.tensor(self.labels[idx])\n",
    "        return {\"input_ids\": input_ids, \"labels\": target_ids}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train = Fraud_EMail_Dataset(encodings=train_encodings, labels=train_labels)\n",
    "test = Fraud_EMail_Dataset(encodings=test_encodings, labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"RELIABLE\", 1: \"UNRELIABLE\"}\n",
    "label2id = {\"RELIABLE\": 0, \"UNRELIABLE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d5a02ff3f54f5bb67c58f22836151a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2609, 'learning_rate': 1.9815157116451017e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1705, 'learning_rate': 1.9630314232902035e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1093, 'learning_rate': 1.944547134935305e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1125, 'learning_rate': 1.9260628465804068e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0698, 'learning_rate': 1.9075785582255083e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0544, 'learning_rate': 1.88909426987061e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0644, 'learning_rate': 1.8706099815157116e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0926, 'learning_rate': 1.8521256931608135e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0465, 'learning_rate': 1.833641404805915e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0441, 'learning_rate': 1.8151571164510168e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1001, 'learning_rate': 1.7966728280961186e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1226, 'learning_rate': 1.77818853974122e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0381, 'learning_rate': 1.759704251386322e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0857, 'learning_rate': 1.7412199630314234e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1082, 'learning_rate': 1.7227356746765253e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1237, 'learning_rate': 1.7042513863216268e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0329, 'learning_rate': 1.6857670979667286e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0227, 'learning_rate': 1.66728280961183e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0397, 'learning_rate': 1.6487985212569316e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0379, 'learning_rate': 1.6303142329020334e-05, 'epoch': 0.18}\n",
      "{'loss': 0.081, 'learning_rate': 1.611829944547135e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0806, 'learning_rate': 1.5933456561922367e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0597, 'learning_rate': 1.5748613678373382e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0001, 'learning_rate': 1.55637707948244e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0464, 'learning_rate': 1.5378927911275416e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0418, 'learning_rate': 1.5194085027726432e-05, 'epoch': 0.24}\n",
      "{'loss': 0.013, 'learning_rate': 1.5009242144177449e-05, 'epoch': 0.25}\n",
      "{'loss': 0.1037, 'learning_rate': 1.4824399260628467e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0346, 'learning_rate': 1.4639556377079484e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0963, 'learning_rate': 1.44547134935305e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0891, 'learning_rate': 1.4269870609981517e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0845, 'learning_rate': 1.4085027726432534e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0881, 'learning_rate': 1.390018484288355e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0001, 'learning_rate': 1.3715341959334567e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0413, 'learning_rate': 1.3530499075785584e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0204, 'learning_rate': 1.33456561922366e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0, 'learning_rate': 1.3160813308687617e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0633, 'learning_rate': 1.2975970425138634e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0458, 'learning_rate': 1.279112754158965e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0, 'learning_rate': 1.2606284658040667e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0208, 'learning_rate': 1.2421441774491683e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0641, 'learning_rate': 1.2236598890942698e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0853, 'learning_rate': 1.2051756007393715e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0429, 'learning_rate': 1.1866913123844732e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0532, 'learning_rate': 1.1682070240295748e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0405, 'learning_rate': 1.1497227356746765e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0, 'learning_rate': 1.1312384473197783e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0, 'learning_rate': 1.11275415896488e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0, 'learning_rate': 1.0942698706099817e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0655, 'learning_rate': 1.0757855822550833e-05, 'epoch': 0.46}\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"fake_news_detector\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"./fake_news_detector/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90405f940c8d468695894c6007e6ea90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/554M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tush9905/fake_news_detector/commit/aab2e3b4024474951f368bf8958cd8020c89e5cc', commit_message='Upload model', commit_description='', oid='aab2e3b4024474951f368bf8958cd8020c89e5cc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"tush9905/fake_news_detector\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
